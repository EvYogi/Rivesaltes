{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bucket_name  = 'edp.engie-digital.prod.instance1.prod.data'\n",
    "num_partitions = 53\n",
    "num_cores = 28 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# point de la station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geocord = scipy.io.loadmat('./geographicCoordinate.mat')['geographicCoordinate']\n",
    "lat = geocord['latitude'][0][0]\n",
    "lon = geocord['longitude'][0][0]\n",
    "latreshape = lat[35:575, 35:795]\n",
    "lonreshape = lon[35:575, 35:795]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latitude_walon = 42.7983\n",
    "longitude_walon = 2.8856\n",
    "distance = np.sqrt((latreshape - latitude_walon)**2+(lonreshape-longitude_walon)**2)\n",
    "pixel_block_matching = np.where(distance == distance.min())\n",
    "pix_block_matching = pixel_block_matching[0][0], pixel_block_matching[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance = np.sqrt((lat - latitude_walon)**2+(lon-longitude_walon)**2)\n",
    "pixel = np.where(distance == distance.min())\n",
    "pix = pixel[0][0], pixel[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 376)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pix_block_matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 411)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.54 s, sys: 95.5 ms, total: 3.64 s\n",
      "Wall time: 7.46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "processed_images = [x.key for x  in bucket.objects.filter(Prefix='LCV_SATELLITE_IMAGE_24/infrared_images/processed/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "processed_images = np.sort(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "available_images = {str(pd.to_datetime(image[-19:-4])):image for image in processed_images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parallelize_dataframe(list_archives, func):\n",
    "    df_split = np.array_split(list_archives, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_irradiance_feature(processed_images):\n",
    "    time = []\n",
    "    outVx = []\n",
    "    outVy = []\n",
    "    out_irradiance = []\n",
    "    zenith = []\n",
    "    azimuth = []\n",
    "\n",
    "    for image in processed_images:\n",
    "        current = str(pd.to_datetime(image[-19:-4])+pd.Timedelta(minutes=15))\n",
    "        if current in available_images.keys():\n",
    "            img_1 = s3_client.get_object(Bucket=bucket_name, Key=image)\n",
    "            img_1_refined = np.array(Image.open(img_1['Body']).convert(\"L\"))\n",
    "            img_2 = s3_client.get_object(Bucket=bucket_name, Key=available_images[current])\n",
    "            img_2_refined = np.array(Image.open(img_2['Body']).convert(\"L\"))\n",
    "\n",
    "            Vx, Vy, X, Y = block_match(img_1_refined,img_2_refined)\n",
    "            Vx_smoothed, Vy_smoothed = smoothing_vectors(Vx, Vy)\n",
    "            Vx_interp, Vy_interp, X_interp, Y_interp = interpolate_vectors(Vx_smoothed, Vy_smoothed, X, Y)\n",
    "            outVx.append(Vx_interp[pix_block_matching[0]-5: pix_block_matching[0]+6,pix_block_matching[1]-5: pix_block_matching[1]+6])\n",
    "            outVy.append(Vy_interp[pix_block_matching[0]-5: pix_block_matching[0]+6,pix_block_matching[1]-5: pix_block_matching[1]+6])\n",
    "            out_irradiance.append(img_2_refined[pix[0]-5: pix[0]+6,pix[1]-5: pix[1]+6])\n",
    "            time.append(current)\n",
    "            \n",
    "            z,a = solar_angles_computation(np.datetime64(current),\n",
    "                                               lat[pix[0]-5: pix[0]+6,pix[1]-5: pix[1]+6],\n",
    "                                               lon[pix[0]-5: pix[0]+6,pix[1]-5: pix[1]+6])\n",
    "            zenith.append(z)\n",
    "            azimuth.append(a)\n",
    "        else:\n",
    "            continue\n",
    "    return pd.DataFrame({'time':time, 'block_matching_vx': outVx, \n",
    "                         'block_matching_vy': outVy, 'brightness':out_irradiance,\n",
    "                         'zenith':zenith, 'azimuth': azimuth\n",
    "                        }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "computed_irradiance_features = parallelize_dataframe(processed_images, compute_irradiance_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21493, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_irradiance_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adnot_data.ipynb\r\n",
      "adnot_data_train.csv\r\n",
      "block_matching_brigtness_temperature_solar_angles_data.ipynb\r\n",
      "block_matching_compute.ipynb\r\n",
      "clearsky_ref.ipynb\r\n",
      "computed_cloud_index_walon.csv\r\n",
      "geographicCoordinate.mat\r\n",
      "rename_infrared.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computed_irradiance_features.to_csv('computed_irradiance_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cloud_index = pd.read_csv('computed_cloud_index_walon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cloud_index.date = pd.to_datetime(cloud_index.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computed_irradiance_features.columns = ['azimuth', 'block_matching_vx', 'block_matching_vy', 'brightness',\n",
    "       'date', 'zenith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computed_irradiance_features.date = pd.to_datetime(computed_irradiance_features.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(computed_irradiance_features, cloud_index, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('dataframe_input_random_forest.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataframe_input_random_forest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>azimuth</th>\n",
       "      <th>block_matching_vx</th>\n",
       "      <th>block_matching_vy</th>\n",
       "      <th>brightness</th>\n",
       "      <th>date</th>\n",
       "      <th>zenith</th>\n",
       "      <th>cloud_index_walon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[109.61015815 109.60888455 109.60760772 109.6...</td>\n",
       "      <td>[[-0.84162397 -0.85872785 -0.87583172 -0.89293...</td>\n",
       "      <td>[[0.49077446 0.4995504  0.50832635 0.51710229 ...</td>\n",
       "      <td>[[106  95  99 100  98  96  97 101 100  97 102]...</td>\n",
       "      <td>2017-01-22 15:30:00</td>\n",
       "      <td>[[93.27648497 93.28440141 93.29231819 93.30023...</td>\n",
       "      <td>[[0.07602339 0.10588235 0.13173653 0.11643836 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[109.53907817 109.53642355 109.5337655  109.5...</td>\n",
       "      <td>[[-0.81299615 -0.82750894 -0.84202174 -0.85653...</td>\n",
       "      <td>[[0.51081341 0.52218043 0.53354746 0.54491448 ...</td>\n",
       "      <td>[[101  93  97  94  93  98 104 105 100  94 109]...</td>\n",
       "      <td>2017-01-22 15:45:00</td>\n",
       "      <td>[[96.80580811 96.8136967  96.82158511 96.82947...</td>\n",
       "      <td>[[0.         0.         0.         0.03797468 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[109.54614777 109.54209206 109.53803266 109.5...</td>\n",
       "      <td>[[-0.85963162 -0.86633112 -0.87303063 -0.87973...</td>\n",
       "      <td>[[0.23691368 0.2412274  0.24554112 0.24985483 ...</td>\n",
       "      <td>[[102 100 103 106 110 109 105 102 101 102 114]...</td>\n",
       "      <td>2017-01-22 16:00:00</td>\n",
       "      <td>[[100.33588665 100.34377771 100.35166805 100.3...</td>\n",
       "      <td>[[0.53757225 0.51829268 0.50967742 0.45859873 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[109.63362497 109.62813952 109.62265003 109.6...</td>\n",
       "      <td>[[-0.73276688 -0.7456406  -0.75851431 -0.77138...</td>\n",
       "      <td>[[0.20544951 0.20664756 0.2078456  0.20904364 ...</td>\n",
       "      <td>[[106 105 107 105 104 104 106 108 108 107 105]...</td>\n",
       "      <td>2017-01-22 16:15:00</td>\n",
       "      <td>[[103.86498849 103.87291321 103.88083665 103.8...</td>\n",
       "      <td>[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[109.80539479 109.79844175 109.79148428 109.7...</td>\n",
       "      <td>[[-0.71167976 -0.73012137 -0.74856297 -0.76700...</td>\n",
       "      <td>[[0.33185455 0.3320181  0.33218165 0.3323452  ...</td>\n",
       "      <td>[[112 100 107 106 104 105 107 108 108 108 112]...</td>\n",
       "      <td>2017-01-22 16:30:00</td>\n",
       "      <td>[[107.39130245 107.39929346 107.40728262 107.4...</td>\n",
       "      <td>[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             azimuth  \\\n",
       "0  [[109.61015815 109.60888455 109.60760772 109.6...   \n",
       "1  [[109.53907817 109.53642355 109.5337655  109.5...   \n",
       "2  [[109.54614777 109.54209206 109.53803266 109.5...   \n",
       "3  [[109.63362497 109.62813952 109.62265003 109.6...   \n",
       "4  [[109.80539479 109.79844175 109.79148428 109.7...   \n",
       "\n",
       "                                   block_matching_vx  \\\n",
       "0  [[-0.84162397 -0.85872785 -0.87583172 -0.89293...   \n",
       "1  [[-0.81299615 -0.82750894 -0.84202174 -0.85653...   \n",
       "2  [[-0.85963162 -0.86633112 -0.87303063 -0.87973...   \n",
       "3  [[-0.73276688 -0.7456406  -0.75851431 -0.77138...   \n",
       "4  [[-0.71167976 -0.73012137 -0.74856297 -0.76700...   \n",
       "\n",
       "                                   block_matching_vy  \\\n",
       "0  [[0.49077446 0.4995504  0.50832635 0.51710229 ...   \n",
       "1  [[0.51081341 0.52218043 0.53354746 0.54491448 ...   \n",
       "2  [[0.23691368 0.2412274  0.24554112 0.24985483 ...   \n",
       "3  [[0.20544951 0.20664756 0.2078456  0.20904364 ...   \n",
       "4  [[0.33185455 0.3320181  0.33218165 0.3323452  ...   \n",
       "\n",
       "                                          brightness                 date  \\\n",
       "0  [[106  95  99 100  98  96  97 101 100  97 102]...  2017-01-22 15:30:00   \n",
       "1  [[101  93  97  94  93  98 104 105 100  94 109]...  2017-01-22 15:45:00   \n",
       "2  [[102 100 103 106 110 109 105 102 101 102 114]...  2017-01-22 16:00:00   \n",
       "3  [[106 105 107 105 104 104 106 108 108 107 105]...  2017-01-22 16:15:00   \n",
       "4  [[112 100 107 106 104 105 107 108 108 108 112]...  2017-01-22 16:30:00   \n",
       "\n",
       "                                              zenith  \\\n",
       "0  [[93.27648497 93.28440141 93.29231819 93.30023...   \n",
       "1  [[96.80580811 96.8136967  96.82158511 96.82947...   \n",
       "2  [[100.33588665 100.34377771 100.35166805 100.3...   \n",
       "3  [[103.86498849 103.87291321 103.88083665 103.8...   \n",
       "4  [[107.39130245 107.39929346 107.40728262 107.4...   \n",
       "\n",
       "                                   cloud_index_walon  \n",
       "0  [[0.07602339 0.10588235 0.13173653 0.11643836 ...  \n",
       "1  [[0.         0.         0.         0.03797468 ...  \n",
       "2  [[0.53757225 0.51829268 0.50967742 0.45859873 ...  \n",
       "3  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0...  \n",
       "4  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\\n [0. 0. 0...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15617"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set.intersection(set(computed_irradiance_features.date), set(cloud_index.date)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "from scipy import signal\n",
    "import json\n",
    "\n",
    "\n",
    "# Parameters & config\n",
    "config = {\n",
    "  \"bucket_S3_name\" : \"octo-rivesaltes\",\n",
    "  \"image_sat_visual_complete\" : \"https://en.sat24.com/image?type=visual5Complete&type=visual5Complete&region=fr&region=fr&timestamp=\",\n",
    "  \"image_sat_infra_polair\" : \"https://en.sat24.com/image?type=infraPolair&type=infraPolair&region=fr&region=fr&timestamp=\",\n",
    "  \"block_matching_size_target_area\" : 41,\n",
    "  \"block_matching_patch\" : 15,\n",
    "  \"block_matching_X\" : 615,\n",
    "  \"block_matching_Y\" : 845\n",
    "}\n",
    "\n",
    "\n",
    "size_target_area = config['block_matching_size_target_area']\n",
    "p = config['block_matching_patch']\n",
    "img_size = (config['block_matching_X'], config['block_matching_Y'])\n",
    "\n",
    "q = int(np.floor(size_target_area/2))\n",
    "\n",
    "x = np.arange(p+q, img_size[0]-(p+q)+1, q)\n",
    "y = np.arange(p+q, img_size[1]-(p+q)+1, q)\n",
    "\n",
    "xvgrid, yvgrid = np.meshgrid(x, y)\n",
    "\n",
    "\n",
    "def _power2(x):\n",
    "    return np.power(x, 2)\n",
    "\n",
    "\n",
    "def _create_gaussian_kernel(sigma, rayon):\n",
    "    sz = 2 * rayon + 1\n",
    "    gaussianKernelFactor = 0\n",
    "    kernel = np.zeros((sz, sz))\n",
    "\n",
    "    for ky in range(-rayon, rayon):\n",
    "        for kx in range(-rayon, rayon):\n",
    "            e = np.exp(- (kx * kx + ky * ky) / (2 * sigma * sigma))\n",
    "            gaussianKernelFactor = gaussianKernelFactor + e\n",
    "            kernel[kx + rayon + 1, ky + rayon + 1] = e\n",
    "    for ky in range(-rayon, rayon):\n",
    "        for kx in range(-rayon, rayon):\n",
    "            kernel[kx + rayon + 1, ky + rayon + 1] = kernel[kx + rayon + 1, ky + rayon + 1] / gaussianKernelFactor\n",
    "\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def patchify(img, patch_shape):\n",
    "    img = np.ascontiguousarray(img)  # won't make a copy if not needed\n",
    "    X, Y = img.shape\n",
    "    x, y = patch_shape\n",
    "    shape = ((X-x+1), (Y-y+1), x, y) # number of patches, patch_shape\n",
    "    # The right strides can be thought by:\n",
    "    # 1) Thinking of `img` as a chunk of memory in C order\n",
    "    # 2) Asking how many items through that chunk of memory are needed when indices\n",
    "    #    i,j,k,l are incremented by one\n",
    "    strides = img.itemsize*np.array([Y, 1, Y, 1])\n",
    "    return np.lib.stride_tricks.as_strided(img, shape=shape, strides=strides)\n",
    "\n",
    "\n",
    "def block_match(img_1, img_2):\n",
    "    \"\"\"\n",
    "    Apply block matching on two images\n",
    "    :param numpy.array img_1: image with grey levels\n",
    "    :param numpy.array img_2: binary encoding of satellite image\n",
    "    :return: numpy.array X,Y,Vx,Vx: Vectors of images block_matched\n",
    "    \"\"\"\n",
    "\n",
    "    if((img_1.shape != img_size)  | (img_2.shape != img_size)):\n",
    "        raise IndexError('Wrong image size')\n",
    "\n",
    "    vectorized_power = np.vectorize(_power2)\n",
    "    img_1_refined = vectorized_power(max(img_1.max(), img_2.max()) - img_1)\n",
    "    img_2_refined = vectorized_power(max(img_1.max(), img_2.max()) - img_2)\n",
    "\n",
    "    X = xvgrid.flatten()\n",
    "    Y = yvgrid.flatten()\n",
    "    Vx = np.array([])\n",
    "    Vy = np.array([])\n",
    "\n",
    "    for x_point, y_point in zip(X, Y):\n",
    "        target_area = img_2_refined[x_point - q:x_point + q + 1, y_point - q:y_point + q + 1]\n",
    "        img_to_patch = img_1_refined[x_point - (q + p):x_point + (q + p + 1), y_point - (q + p):y_point + (q + p + 1)]\n",
    "        results = patchify(img_to_patch, target_area.shape)\n",
    "        error = abs(results - target_area)\n",
    "        costs = np.apply_over_axes(np.mean, error, [2, 3]).reshape(error.shape[0:2])\n",
    "        x_patch_most_likely, y_patch_most_likely = np.where(costs == costs.min())\n",
    "        Vx = np.append(Vx, p - x_patch_most_likely[0])\n",
    "        Vy = np.append(Vy, p - y_patch_most_likely[0])\n",
    "\n",
    "    return Vx, Vy, X, Y\n",
    "\n",
    "\n",
    "def smoothing_vectors(Vx, Vy):\n",
    "    \"\"\"\n",
    "    smooth values from vectors Vx and Vy\n",
    "    :param numpy.ndarray Vx: Vectors of coordinates on axis X\n",
    "    :param numpy.ndarray Vy: Vectors of coordinates on axis Y\n",
    "    :param tuple shape : Size to reshape the vectors in a matrix (cf xvgrid)\n",
    "    :return: numpy.ndarray Vx,Vx: Vectors of coordinates smoothed\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = _create_gaussian_kernel(sigma=1, rayon=2)\n",
    "    Vx = signal.convolve2d(Vx.reshape(xvgrid.shape), kernel, 'same')\n",
    "    Vy = signal.convolve2d(Vy.reshape(xvgrid.shape), kernel, 'same')\n",
    "\n",
    "    return Vx, Vy\n",
    "\n",
    "\n",
    "def interpolate_vectors(Vx, Vy, X, Y):\n",
    "    \"\"\"\n",
    "    intepolate values from vectors Vx and Vy\n",
    "    :param numpy.ndarray X: points of coordinates on axis X\n",
    "    :param numpy.ndarray Y: points of coordinates on axis Y\n",
    "    :param numpy.ndarray Vx: Vectors of coordinates on axis X\n",
    "    :param numpy.ndarray Vy: Vectors of coordinates on axis Y\n",
    "    :param tuple shape : Size to reshape the vectors in a matrix (cf xvgrid)\n",
    "    :return: numpy.ndarray Vx,Vx: Vectors of coordinates interpolated\n",
    "    \"\"\"\n",
    "\n",
    "    grid_x, grid_y = np.mgrid[min(X):max(X), min(Y):max(Y)]\n",
    "    arr = np.array((X.reshape(xvgrid.shape)[~np.isnan(Vx)].flatten(),\n",
    "                    Y.reshape(xvgrid.shape)[~np.isnan(Vy)].flatten())).transpose()\n",
    "\n",
    "    Vx = griddata(arr, Vx[~np.isnan(Vx)].flatten(), (grid_x, grid_y), method='linear')\n",
    "    Vy = griddata(arr, Vy[~np.isnan(Vy)].flatten(), (grid_x, grid_y), method='linear')\n",
    "\n",
    "    return Vx, Vy, grid_x, grid_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def day_of_the_year_computation(universal_time):\n",
    "    \"\"\"\n",
    "    Computes the floating value for the day of the year\n",
    "    :param numpy.datetime64 universal_time:\n",
    "    :return: float day of year:\n",
    "    \"\"\"\n",
    "    time_object = pd.to_datetime(universal_time)\n",
    "    return time_object.dayofyear + time_object.hour/24.0 + time_object.minute/(24.0*60)\n",
    "\n",
    "\n",
    "def solar_angles_computation(universal_time, longitude, latitude):\n",
    "    \"\"\"\n",
    "    Computes the zenith matrix associated with longitude, latitude at a given universal time,\n",
    "    reference NOAA Global Monitoring Division\n",
    "    :param numpy.datetime64 universal_time: universal time\n",
    "    :param numpy.ndarray longitude: array of the considered longitude\n",
    "    :param numpy.ndarray latitude: array of the considered latitude\n",
    "    :return:numpy.ndarray zenith: matrix of the zenith in degrees\n",
    "    :return:numpy.ndarray azimuth: matrix of the azimuth in degrees\n",
    "    \"\"\"\n",
    "    if longitude.shape == latitude.shape:\n",
    "        day_of_year = day_of_the_year_computation(universal_time)\n",
    "        x = 2 * np.pi / 365 * (day_of_year - 1)  # day of year un radian, named x because heavily referenced\n",
    "\n",
    "        eqtime = (0.000075 + 0.001868 * np.cos(x) - 0.032077 * np.sin(x) - 0.014615 * np.cos(2 * x)\n",
    "                  - 0.040849 * np.sin(2 * x)) * ((24 * 60) / (2 * np.pi))\n",
    "\n",
    "        solar_declination = 0.006918 - 0.399912 * np.cos(x) + 0.070257 * np.sin(x) \\\n",
    "                            - 0.006758 * np.cos(2 * x) + 0.000907 * np.sin(2 * x) \\\n",
    "                            - 0.002697 * np.cos(3 * x) + 0.001480 * np.sin(3 * x)\n",
    "\n",
    "        longitude_corrected = 4*longitude\n",
    "        offset = (longitude_corrected + eqtime).astype('timedelta64[m]')\n",
    "        true_solar_time = offset + universal_time\n",
    "        true_solar_time = [x.astype(object) for x in true_solar_time.flatten()]\n",
    "        true_solar_time_minutes = [(lambda time: (time.hour*60 + time.minute + time.second/60))(time)\n",
    "                                   for time in true_solar_time]\n",
    "\n",
    "        hour_angle = np.array([(x/4 - 180)*np.pi/180 for x in true_solar_time_minutes]).reshape(latitude.shape)\n",
    "        zenith = np.arccos(np.cos(solar_declination)*np.cos(latitude*np.pi/180)*np.cos(hour_angle)\n",
    "                           + np.sin(solar_declination)*np.sin(latitude*np.pi/180))\n",
    "\n",
    "        azimuth = np.arccos((np.sin(solar_declination) * np.cos(latitude * np.pi / 180) - np.cos(solar_declination)\n",
    "                           * np.sin(latitude * np.pi / 180) * np.cos(hour_angle)) / np.sin(zenith))\n",
    "\n",
    "        return zenith * 180 / np.pi, azimuth * 180 / np.pi\n",
    "    else:\n",
    "        return ValueError\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
